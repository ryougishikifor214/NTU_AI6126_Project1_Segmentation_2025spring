{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "from global_config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifiable Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bisenetv2/bisenetv2_fcn_4xb8-160k_cityscapes-1024x1024.py'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_MODEL_CONFIG_DIR = CONFIG_BISENETV2_FCN_DIR_PATH\n",
    "WORK_DIR = OUT_BISENETV2_FCN_DIR_PATH\n",
    "MODEL_CFG_NAME = \"bisenetv2_fcn\"\n",
    "mmseg_model_cfg_suffix_path = \"bisenetv2/bisenetv2_fcn_4xb8-160k_cityscapes-1024x1024.py\"\n",
    "# mmseg_model_cfg_path = Path(MMSEG_MODEL_CONFIG_DIR_PATH)/Path(mmseg_model_cfg_subdir)\n",
    "mmseg_model_cfg_suffix_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/featurize/work/AI6126project1/mmsegmentation/configs/bisenetv2/bisenetv2_fcn_4xb8-160k_cityscapes-1024x1024.py\n"
     ]
    }
   ],
   "source": [
    "mmseg_model_cfg_path = os.path.join(MMSEG_MODEL_CONFIG_DIR_PATH, mmseg_model_cfg_suffix_path)\n",
    "print(mmseg_model_cfg_path)\n",
    "\n",
    "cfg = Config.fromfile(mmseg_model_cfg_path)\n",
    "celeba_pipeline_cfg = Config.fromfile(CELEBA_PIPELINE_PATH)\n",
    "cfg.merge_from_dict(celeba_pipeline_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Modifiable\n",
    "cfg.model.backbone.norm_cfg = NORM_CFG\n",
    "cfg.norm_cfg = NORM_CFG \n",
    "cfg.data_preprocessor = DATA_PREPROCESSOR\n",
    "cfg.model.data_preprocessor = DATA_PREPROCESSOR\n",
    "\n",
    "for i in range(len(cfg.model.auxiliary_head)):\n",
    "    cfg.model.auxiliary_head[i].norm_cfg = NORM_CFG\n",
    "    cfg.model.auxiliary_head[i].num_classes = NUM_CLASS\n",
    "    \n",
    "cfg.model.decode_head.num_classes = NUM_CLASS\n",
    "\n",
    "cfg.work_dir = WORK_DIR\n",
    "cfg.train_dataloader.batch_size = 8\n",
    "\n",
    "cfg.train_cfg.max_iters = 30000\n",
    "cfg.train_cfg.val_interval = 500 \n",
    "cfg.default_hooks.logger.interval = 100 \n",
    "cfg.default_hooks.checkpoint.interval = 500\n",
    "cfg.default_hooks.checkpoint.max_keep_ckpts = 2\n",
    "cfg.default_hooks.checkpoint.save_best = 'mIoU'\n",
    "cfg.default_hooks.checkpoint.rule = \"greater\"\n",
    "\n",
    "cfg['randomness'] = dict(seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model.decode_head.loss_decode = weighted_CE_lovasz_dice_loss_decode\n",
    "# for i in range(len(cfg.model.auxiliary_head)):\n",
    "#     cfg.model.auxiliary_head[i].loss_decode = weighted_CE_lovasz_dice_loss_decode_auxiliary\n",
    "\n",
    "for i in range(len(cfg.model.auxiliary_head)):\n",
    "    cfg.model.auxiliary_head[i].loss_decode.class_weight = class_weights\n",
    "    cfg.model.auxiliary_head[i].loss_decode.loss_weight *= 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xs 1.7M\n",
    "cfg.model.backbone.detail_channels = (32, 64, 96)\n",
    "cfg.model.backbone.semantic_channels = (16, 32, 64, 96)\n",
    "cfg.model.backbone.bga_channels = 96\n",
    "cfg.model.backbone.out_indices = (0,1,2,3,4)\n",
    "cfg.model.backbone.semantic_expansion_ratio = 6\n",
    "\n",
    "cfg.model.decode_head.in_channels = 96\n",
    "cfg.model.decode_head.channels = 512\n",
    "cfg.model.decode_head.in_index = 0\n",
    "\n",
    "cfg.model.auxiliary_head[0].in_channels = 16\n",
    "cfg.model.auxiliary_head[0].channels = 16\n",
    "cfg.model.auxiliary_head[0].in_index = 1\n",
    "cfg.model.auxiliary_head[1].in_channels = 32\n",
    "cfg.model.auxiliary_head[1].channels = 32\n",
    "cfg.model.auxiliary_head[1].in_index = 2\n",
    "cfg.model.auxiliary_head[2].in_channels = 64\n",
    "cfg.model.auxiliary_head[2].channels = 64\n",
    "cfg.model.auxiliary_head[2].in_index = 3\n",
    "cfg.model.auxiliary_head[3].in_channels = 96\n",
    "cfg.model.auxiliary_head[3].channels = 128\n",
    "cfg.model.auxiliary_head[3].in_index = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.optimizer = dict(lr=0.0075, momentum=0.9, weight_decay=0.001, type='SGD')\n",
    "cfg.optim_wrapper = dict(type='OptimWrapper', optimizer=cfg.optimizer)\n",
    "cfg.param_scheduler = [\n",
    "    dict(begin=0, by_epoch=False, end=1000, start_factor=0.2, type='LinearLR'), \n",
    "    dict(\n",
    "        begin=1000,\n",
    "        by_epoch=False,\n",
    "        end=cfg.train_cfg.max_iters,   \n",
    "        eta_min=5e-5,  \n",
    "        power=0.95,\n",
    "        type='PolyLR'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #s 2.2M\n",
    "# cfg.model.backbone.detail_channels = (32, 64, 128)\n",
    "# cfg.model.backbone.semantic_channels = (16, 32, 64, 128)\n",
    "# cfg.model.backbone.bga_channels = 128\n",
    "# cfg.model.backbone.out_indices = (0,1,2,3)\n",
    "# cfg.model.backbone.semantic_expansion_ratio = 6\n",
    "\n",
    "# cfg.model.decode_head.in_channels = 128\n",
    "# cfg.model.decode_head.channels = 128\n",
    "# cfg.model.decode_head.in_index = 0\n",
    "\n",
    "# cfg.model.auxiliary_head[0].in_channels = 16\n",
    "# cfg.model.auxiliary_head[0].channels = 16\n",
    "# cfg.model.auxiliary_head[0].in_index = 1\n",
    "# cfg.model.auxiliary_head[1].in_channels = 32\n",
    "# cfg.model.auxiliary_head[1].channels = 32\n",
    "# cfg.model.auxiliary_head[1].in_index = 2\n",
    "# cfg.model.auxiliary_head[2].in_channels = 64\n",
    "# cfg.model.auxiliary_head[2].channels = 64\n",
    "# cfg.model.auxiliary_head[2].in_index = 3\n",
    "\n",
    "# del cfg.model.auxiliary_head[3]\n",
    "\n",
    "# # cfg.model.auxiliary_head[3].in_channels = 96\n",
    "# # cfg.model.auxiliary_head[3].channels = 128\n",
    "# # cfg.model.auxiliary_head[3].in_index = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(mmseg_model_cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/featurize/work/AI6126project1/assets/model_configs/bisenetv2_fcn/celeba_bisenetv2_fcn_20250327.py'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "ymd_timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "cfg.dump(os.path.join(FINAL_MODEL_CONFIG_DIR, f\"celeba_{MODEL_CFG_NAME}_{ymd_timestamp}.py\"))\n",
    "os.path.join(FINAL_MODEL_CONFIG_DIR, f\"celeba_{MODEL_CFG_NAME}_{ymd_timestamp}.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
